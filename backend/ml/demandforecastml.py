# -*- coding: utf-8 -*-
"""DemandForecastML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/178ftpfnjsusVB9pXv2OKa3cyw6WQGjtI

Imports
"""

!pip install scikit-optimize

# Data manipution and visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# machine learning models
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import VotingRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

# Cross Validation
from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV
from skopt import BayesSearchCV

# Evaluation
from sklearn.metrics import r2_score, mean_squared_error
import math

df = pd.read_csv('/content/item_and_store_details.csv')
df

df.shape

df.describe()

df.info()

# date column is in object data-type. Converting that into date datatype
df['date'] = pd.to_datetime(df['date'])

df.info()

# Checking for null values
df.isnull().sum()

df = df.groupby(['item', 'date'], as_index=False)['sales'].agg({'sales':'sum'})

df

for i in range(1, 51):
    df.loc[df['item'].isin([i]), 'sales'] = df.loc[df['item'].isin([i]), 'sales'].rolling(90, center=True, min_periods=1).sum().fillna(0)

df

df['year'] = df['date'].dt.year
df['month']= df['date'].dt.month
df['day'] = df['date'].dt.day
df['week'] = df['date'].dt.week
df['day_of_week'] = df['date'].dt.day_of_week
df['day_of_year'] = df['date'].dt.day_of_year
df['day_in_month'] = df['date'].dt.days_in_month
df['quarter'] = df['date'].dt.quarter
df['is_leap_year'] = df['date'].dt.is_leap_year
df['is_month_start'] = df['date'].dt.is_month_start
df['is_month_end'] = df['date'].dt.is_month_end
df['is_quarter_start'] = df['date'].dt.is_quarter_start
df['is_quarter_end'] = df['date'].dt.is_quarter_end
df['is_year_start'] = df['date'].dt.is_year_start
df['is_year_end'] = df['date'].dt.is_year_end

df.head()

# Encoding
df['is_leap_year'] = (df['is_leap_year']==True).astype(int)
df['is_month_start'] = (df['is_month_start']==True).astype(int)
df['is_month_end'] = (df['is_month_end']==True).astype(int)
df['is_quarter_start'] = (df['is_quarter_start']==True).astype(int)
df['is_quarter_end'] = (df['is_quarter_end']==True).astype(int)
df['is_year_start'] = (df['is_year_start']==True).astype(int)
df['is_year_end'] = (df['is_year_end']==True).astype(int)

df.head()

# Heatmap
plt.figure(figsize=(16, 10))
sns.heatmap(data=df[['sales', 'year', 'month', 'day', 'week', 'day_of_week', 'day_of_year', 'day_in_month', 'quarter', 'is_leap_year', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'is_year_start', 'is_year_end']].corr(),annot=True)

# Sales throughout the years
plt.figure(figsize=(16, 6))
df.set_index('date')['sales'].groupby('date').sum().plot(kind='line')
plt.title('Sales throughout the years')
plt.ylabel('sales')
plt.show()

df.groupby(['month', 'year']).agg({'sales':'sum'}).unstack().plot(kind='line', figsize=(16, 6))

# Sales of each item through out the years
c = ['red', 'green', 'yellow', 'orange', 'purple']
fig, axs = plt.subplots(10, 5, figsize=(16, 40))
k = 0
for i in range(10):
    for j in range(5):
        k += 1
        axs[i, j].plot(df[['year', 'sales']][df['item']==k], color=c[j])

df_train = df[df['year']!=2017].reset_index(drop=True)
df_test = df[df['year']==2017].reset_index(drop=True)

plt.figure(figsize=(16, 6))
df_train.set_index('date')['sales'].groupby('date').sum().plot(kind='line', color='green')
df_test.set_index('date')['sales'].groupby('date').sum().plot(kind='line', color='red')
plt.title('Train and Test Split')
plt.ylabel('sales')
plt.show()

df.head()

x_train = df_train.drop(['date', 'sales'], axis=1).values
x_test = df_test.drop(['date', 'sales'], axis=1).values

y_train = df_train['sales'].values
y_test = df_test['sales'].values

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit_transform(x_train)
sc.fit(x_test)

x_train

"""MODELS

Linear Regression
"""

lr = LinearRegression()
lr.fit(x_train, y_train)

r2_score(y_test, lr.predict(x_test))

"""K Nearest Neighbors"""

knn = KNeighborsRegressor()
knn.fit(x_train, y_train)

r2_score(y_test, knn.predict(x_test))

"""Decision Tree"""

dt = DecisionTreeRegressor()
dt.fit(x_train, y_train)

r2_score(y_test, dt.predict(x_test))

"""Random Forest"""

rf = RandomForestRegressor()
rf.fit(x_train, y_train)

r2_score(y_test, rf.predict(x_test))

"""XGBoost"""

xgb = XGBRegressor()
xgb.fit(x_train, y_train)

r2_score(y_test, xgb.predict(x_test))

"""Time Series Cross Validation"""

df_train['year'].unique()

def timeseriescv(model):

    '''Used to do time series cross validation with given regressor model.
    R2 Score is used for Evaluation and the mean score of 4 validation in time series data will be the output.
    model --> The model we use for cross validation. Ex: XGBregressor()'''

    ## Creating first split for time series cross validation
    # Initially using data of 2013 and 2014 as training and the data of next 6 months after the year 2014 is used as a test
    tsdf_train = df_train[df_train['year'].isin([2013, 2014])]
    tsdf_test = df_train[~df_train['year'].isin([2013, 2014])]

    # Creating split for model
    tsx_train = tsdf_train.drop(['sales', 'date'], axis=1).values
    tsy_train = tsdf_train['sales'].values

    tsx_test = tsdf_test[(tsdf_test['year']==2015) & (tsdf_test['month'].isin([1, 2, 3, 4, 5, 6]))].drop(['sales', 'date'], axis=1).reset_index(drop=True).values
    tsy_test = tsdf_test[(tsdf_test['year']==2015) & (tsdf_test['month'].isin([1, 2, 3, 4, 5, 6]))]['sales'].reset_index(drop=True).values

    score_list = []
    y = [2015, 2016, 2016]

    for i in range(3):

        ## model and score appendation
        model = model
        model.fit(tsx_train, tsy_train)
        score_list.append(r2_score(tsy_test, model.predict(tsx_test)))

        ## updating split
        tsx_train = pd.concat([pd.DataFrame(tsx_train), pd.DataFrame(tsx_test)], ignore_index=True).values
        tsy_train = pd.concat([pd.DataFrame(tsy_train), pd.DataFrame(tsy_test)], ignore_index=True).values
        if i%2==0:
            m = [7, 8, 9, 10, 11, 12]
        else:
            m = [1, 2, 3, 4, 5, 6,]
        tsx_test = df_train[(df_train['year']==y[i]) & (df_train['month'].isin(m))].drop(['sales', 'date'], axis=1).reset_index(drop=True).values
        tsy_test = df_train[(df_train['year']==y[i]) & (df_train['month'].isin(m))]['sales'].reset_index(drop=True).values

    ## Cross_validation Score
    return np.mean(score_list)

"""Decision Tree with Cross Validation"""

d, m_score = 0, 0
for i in range(3, 40):
    res = timeseriescv(DecisionTreeRegressor(max_depth=i))
    if res>m_score:
        d, m_score = i, res
print(f'max_score: {m_score} and max_depth: {d}')

dt = DecisionTreeRegressor(max_depth=32)
dt.fit(x_train, y_train)

r2_score(y_test, dt.predict(x_test))

"""XGBoost with Cross Validation"""

xgb = XGBRegressor(learning_rate=0.8, max_depth=22, min_child_weight=5, subsample=0.7, colsample_bytree=0.7, n_estimators=500)
xgb.fit(x_train, y_train)

r2_score(y_test, xgb.predict(x_test))

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score
import numpy as np
import pandas as pd

def knn_timeseriescv():
    '''Perform time series cross-validation with KNN regressor.
    Returns the mean R-squared score over all folds.'''

    # Initialize KNN regressor
    knn = KNeighborsRegressor()

    # Initialize score list
    score_list = []

    # Define years for splitting
    years = [2015, 2016, 2016]

    for i in range(3):
        # Create training and test sets for current fold
        train_mask = (df_train['year'].isin([2013, 2014])) | ((df_train['year'] == years[i]) & (df_train['month'] <= 6))
        test_mask = (df_train['year'] == years[i]) & (df_train['month'].isin([7, 8, 9, 10, 11, 12])) if i % 2 == 0 else \
                    (df_train['year'] == years[i]) & (df_train['month'].isin([1, 2, 3, 4, 5, 6]))

        tsx_train = df_train[train_mask].drop(['sales', 'date'], axis=1).values
        tsy_train = df_train[train_mask]['sales'].values

        tsx_test = df_train[test_mask].drop(['sales', 'date'], axis=1).values
        tsy_test = df_train[test_mask]['sales'].values

        # Fit KNN regressor
        knn.fit(tsx_train, tsy_train)

        # Make predictions
        predictions = knn.predict(tsx_test)

        # Calculate R-squared score
        score = r2_score(tsy_test, predictions)

        # Append score to list
        score_list.append(score)

    # Return mean R-squared score
    return np.mean(score_list)

# Call function to perform time series cross-validation with KNN
cv_score = knn_timeseriescv()
print("Mean R-squared score using time series cross-validation with KNN:", cv_score)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd

def logistic_regression_timeseriescv():
    '''Perform time series cross-validation with Logistic Regression.
    Returns the mean accuracy score over all folds.'''

    # Initialize Logistic Regression model
    lr = LogisticRegression()

    # Initialize score list
    score_list = []

    # Define years for splitting
    years = [2015, 2016, 2016]

    for i in range(3):
        # Create training and test sets for current fold
        train_mask = (df_train['year'].isin([2013, 2014])) | ((df_train['year'] == years[i]) & (df_train['month'] <= 6))
        test_mask = (df_train['year'] == years[i]) & (df_train['month'].isin([7, 8, 9, 10, 11, 12])) if i % 2 == 0 else \
                    (df_train['year'] == years[i]) & (df_train['month'].isin([1, 2, 3, 4, 5, 6]))

        tsx_train = df_train[train_mask].drop(['target_column', 'date'], axis=1).values
        tsy_train = df_train[train_mask]['target_column'].values

        tsx_test = df_train[test_mask].drop(['target_column', 'date'], axis=1).values
        tsy_test = df_train[test_mask]['target_column'].values

        # Fit Logistic Regression model
        lr.fit(tsx_train, tsy_train)

        # Make predictions
        predictions = lr.predict(tsx_test)

        # Calculate accuracy score
        score = accuracy_score(tsy_test, predictions)

        # Append score to list
        score_list.append(score)

    # Return mean accuracy score
    return np.mean(score_list)

# Call function to perform time series cross-validation with Logistic Regression
cv_score_lr = logistic_regression_timeseriescv()
print("Mean accuracy score using time series cross-validation with Logistic Regression:", cv_score_lr)

"""Important Features"""

columns = df_train.drop(['date', 'sales'], axis=1).columns

xgb.feature_importances_

imp_feat = pd.DataFrame({'ft':columns, 'imp':xgb.feature_importances_})
imp_feat.sort_values('imp', ascending=False, inplace=True)

imp_feat.iloc[:9, 0].values

print(list(columns))

list(pd.DataFrame(x_train).columns)

imp_fts_data = pd.DataFrame(x_train).loc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8]]
imp_fts_data = imp_fts_data.values

imp_fts_test = pd.DataFrame(x_test).loc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8]].values

imp_fts_data

imp_fts_test

xgbif = XGBRegressor(learning_rate=0.8, max_depth=22, min_child_weight=5, subsample=0.7, colsample_bytree=0.7, n_estimators=500)
xgbif.fit(imp_fts_data, y_train)

r2_score(y_test, xgbif.predict(imp_fts_test))

from sklearn.metrics import mean_absolute_error

# Assuming y_test is the actual target values and imp_fts_test are the features for the test set
# Assuming xgbif is the trained XGBoost model

# Get the predicted labels
predicted_labels = xgbif.predict(imp_fts_test)

# Calculate Mean Absolute Error
mae = mean_absolute_error(y_test, predicted_labels)

# Print MAE
print("Mean Absolute Error:", mae)

import matplotlib.pyplot as plt

# Assuming y_test are the actual target values
# Assuming predicted_labels are the predicted values

# Create scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(y_test, predicted_labels, color='blue', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')
plt.title('Actual vs. Predicted')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()